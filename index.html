<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="InT: Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning" />
    <meta property="og:title" content="InT: Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning" />
    <meta
      property="og:description"
      content="InT: Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning"
    />
    <meta property="og:url" content="https://intervention-training.github.io/" />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="static/image/overview.png" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="630" />

    <meta name="twitter:title" content="InT: Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning" />
    <meta
      name="twitter:description"
      content="InT: Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning"
    />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta
      name="twitter:image"
      content="static/image/overview.png"
    />
    <meta name="twitter:card" content="static/image/overview.png" />
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords" content="InT: Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>InT</title>
    <link rel="icon" type="image/x-icon" href="static/images/icon.png" />
    <link
      href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
      rel="stylesheet"
    />

    <link rel="stylesheet" href="static/css/bulma.min.css" />
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css" />
    <link rel="stylesheet" href="static/css/bulma-slider.min.css" />
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css" />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"
    />
    <link rel="stylesheet" href="static/css/index.css" />
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
      tailwind.config = {
        prefix: 'tw-', // This makes all Tailwind classes start with 'tw-'
      };
    </script>
  </head>
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h2 class="title is-2 publication-title ">
                <span style="font-family: monospace;">InT</span>: Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning
              </h2>
              <div class="is-size-5 publication-authors">
                <!-- Paper authors -->
                <span class="author-block">
                  <a href="https://matthewyryang.com/" target="_blank"
                  >Matthew Y. R. Yang<sup>1</sup></a
                  >
                  ,
                </span>
                <span class="author-block">
                  <a href="https://biechi.github.io/" target="_blank"
                  >Hao Bai<sup>2</sup></a
                  >
                  ,
                </span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=QdfBJmAAAAAJ&hl=en" target="_blank"
                  >Ian Wu<sup>1</sup></a
                  >
                  ,
                </span>
                <span class="author-block">
                  <a href="https://www.linkedin.com/in/gene--yang/" target="_blank"
                  >Gene Yang<sup>1</sup></a
                  >
                  ,
                </span>
                <span class="author-block">
                  <a href="https://ars22.github.io/" target="_blank"
                    >Amrith Setlur<sup>1</sup></a
                  >
                  ,
                </span>
                <span class="author-block">
                  <a href="https://aviralkumar2907.github.io/" target="_blank"
                    >Aviral Kumar<sup>1</sup></a
                  >
                </span>
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block">
                  <sup>1</sup>Carnegie Mellon University,
                  <sup>2</sup>University of Illinois Urbana-Champaign
                </span>
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- ArXiv abstract Link -->
                  <span class="link-block">
                    <a
                      href="https://arxiv.org/abs/2506.09026"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arXiv</span>
                    </a>
                  </span>

                  <!-- <span class="link-block">
                    <a
                      href="https://www.youtube.com/watch?v=Qv8aTLthfhs"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="fab fa-youtube"></i>
                      </span>
                      <span>Video</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a
                      href="https://huggingface.co/d1shs0ap"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <!-- <i class="fab fa-huggingface"></i> -->
                        <img src="static/images/hf-logo.svg" alt="Hugging Face" style="width: 20px; height: 20px;">
                      </span>
                      <span>Data and Model (Coming Soon)</span>
                    </a>
                  </span>
                  <span class="link-block">
                    <a
                      href="https://github.com/matthewyryang/int"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code (Coming Soon)</span>
                    </a>
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="has-text-centered">
        <div class="text-center">
          <img src="static/images/fig1-new.gif" alt="InT: Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning" class="mx-auto"/>
        </div>
      </div>
      <p class="tw-text-left tw-text-sm tw-text-gray-500 tw-mt-4">
        <b>Intervention training (<span style="font-family: monospace;">InT</span>) for improving credit assignment.</b>  <span style="font-family: monospace;">InT</span> proposes <i>single-step</i> interventions to replace incorrect intermediate steps in reasoning traces (1). Conditioned on these localized corrections, the model can generate counterfactual continuations that succeed where the original failed (2). We then perform supervised fine-tuning on these interventions, enabling effective credit assignment by upweighting the likelihood of the interventions in place of the mistakes.
      </p>
    </div>
  </div>
</section>
    <!-- End teaser video -->

    <!-- Paper abstract -->
    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                Outcome-reward reinforcement learning (RL) has proven effective at improving the reasoning capabilities of large language models (LLMs). However, standard RL assigns credit only at the level of the final answer, penalizing entire reasoning traces when the outcome is incorrect and uniformly reinforcing all steps when it is correct. As a result, correct intermediate steps may be discouraged in failed traces, while spurious steps may be reinforced in successful ones. We refer to this failure mode as the problem of <i>credit assignment</i>. While a natural remedy is to train a process reward model, accurately optimizing such models to identify corrective reasoning steps remains challenging. We introduce <b>Intervention Training</b> (<span style="font-family: monospace;">InT</span>), a training paradigm in which the model performs fine-grained credit assignment on its own reasoning traces by proposing short, targeted corrections that steer trajectories toward higher reward. Using reference solutions commonly available in mathematical reasoning datasets and exploiting the fact that verifying a model-generated solution is easier than generating a correct one from scratch, the model identifies the first error in its reasoning and proposes a single-step <i>intervention</i> to redirect the trajectory toward the correct solution. We then apply supervised fine-tuning (SFT) to the on-policy rollout up to the point of error concatenated with the intervention, localizing error to the specific step that caused failure. We show that the resulting model serves as a far better initialization for RL training. After running <span style="font-family: monospace;">InT</span> and subsequent fine-tuning with RL, we improve accuracy by nearly 14% over a 4B-parameter base model on IMO-AnswerBench, outperforming larger open-source models such as <span style="font-family: monospace;">gpt-oss-20b</span>.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End paper abstract -->
    
    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full-width">
            <!-- <details>
              <summary style="font-size: 2rem; font-weight: bold; cursor: pointer;">Problem Statement: Optimizing & Extrapolating Test-Time Compute</summary> -->
            <h2 class="title is-3" id="setup">Motivation</h2>
              <!-- <h3 class="title is-4">Experiment Setup</h3> -->
              <div class="content has-text-justified">
                <p>
                  Upon receiving zero reward, outcome-based RL methods like GRPO cannot pinpoint which specific reasoning steps led to the incorrect final answer. Instead, it downweights the entire trajectory. What we really want is to identify the exact locations of mistakes and penalize only those steps.
                  How can we do this without expensive rollouts or training PRMs? In this work, we leverage the strong verification abilities of LLMs to construct a more informative learning signal. 
                </p>
                <!-- <div style="display: flex; justify-content: center; gap: 20px; align-items: center;"><img
                  src="static/images/aime_line.png"
                  alt="open-source models"
                  width="50%"
                /> -->
                <!-- <p></p> -->
                </p>
              </div>
              </div>
            </div>
          <!-- </details> -->
          </div>
        </div>
      </div>
    </section>
    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full-width">
            <!-- <details>
              <summary style="font-size: 2rem; font-weight: bold; cursor: pointer;">Problem Statement: Optimizing & Extrapolating Test-Time Compute</summary> -->
            <h2 class="title is-3" id="setup"><span style="font-family: monospace;">InT</span>: Self-Proposed Interventions</h2>
              <!-- <h3 class="title is-4">Experiment Setup</h3> -->
              <div class="content has-text-justified">
                <p>In our method, we correct an incorrect rollout by intervening at the exact point of error. We do the following:</p>
                <ol>
                  <li><b>Self-verify:</b> Given the incorrect rollout and a reference solution, the base model verifies each step in the incorrect rollout.</li>
                  <li><b>Propose intervention:</b> After locating the first mistake, the base model proposes an <i>intervention</i> in replacement of the erroneous step to steer the remainder of the trajectory toward the correct answer.</li>
                </ol>
                <p>
                  After generating the interventions, we perform SFT on them and then downstream RL.
                </p>
                <div style="display: flex; justify-content: center;">
                  <img src="static/images/fig1.png" alt="" style="width: 80%;" />
                </div>
              </div>
          <!-- </details> -->
          </div>
        </div>
      </div>
    </section>
    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full-width">
            <!-- <details>
              <summary style="font-size: 2rem; font-weight: bold; cursor: pointer;">Problem Statement: Optimizing & Extrapolating Test-Time Compute</summary> -->
            <h2 class="title is-3" id="setup">On-policiness is correlated with better performance</h2>
              <!-- <h3 class="title is-4">Experiment Setup</h3> -->
              <div class="content has-text-justified">
                <p>We compare SFT on interventions against performing SFT on other forms of data. They include:</p>
                <ol>
                  <li><b>Reference Solution:</b> solutions written by humans or the Gemini-2.5 Pro model</li>
                  <li><b>R1 Think, R1 Summary:</b> DeepSeek-R1 generated content inside and after the <span style="font-family: monospace;">&lt;think&gt;</span> tags, respectively.</li>
                  <li><b>Self-reflection:</b> created by prompting the base model to rewrite incorrect rollouts <i>entirely</i> given a reference solution.</li>
                </ol>
                <div style="display: flex; gap: 10px; text-align: center; margin-top: 10px; justify-content: center;">
                  <div><img src="static/images/nll.png"></div>
                  <div><img src="static/images/off_policy_train_pass_at_k.png"></div>
                  <div><img src="static/images/off_policy_test_pass_at_k.png"></div>
                </div>
                <p class="tw-text-left tw-text-sm tw-text-gray-500 tw-mt-4">
                  <b>(left)</b> Average negative log-likelihood (NLL) computed over 64 sampled traces.  <b>(middle)</b> Train pass@k on 64 sampled training problems. InT achieves the highest pass@k. <b>(right)</b> Test pass@ùëò on IMO-Bench, AMO-Bench, and Apex Shortlist. InT again attains the best pass@k.
                </p>
                <p>
                  As shown above, we observe a correlation between the "on-policiness" (i.e., likelihood under base model) of SFT data and the post-SFT performance. <span style="font-family: monospace;">InT</span> traces are the most on-policy, and lead to the best performance, whereas reference solutions are the least on-policy, and consistently lead to the worst performance.
                </p>
              </div>
          <!-- </details> -->
          </div>
        </div>
      </div>
    </section>
    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full-width">
            <!-- <details> -->
              <!-- <summary style="font-size: 2rem; font-weight: bold; cursor: pointer;">Final Results with <span style="font-family: monospace;">e3</span>: State-of-the-art &lt; 2B Model on AIME and HMMT‚Äô25</summary> -->
            <h2 class="title is-3" id="setup">Final Results</h2>
            <div class="content has-text-justified">
              <p>
                So <span style="font-family: monospace;">InT</span> leads to the highest post-SFT pass@k, and therefore provides a good initialization for online RL to reinforce the learned interventions. In the table below, we report the downstream RL performance on several benchmarks, evaluated at 16K tokens.
              </p>
              <p>
                Notably, initializing RL with <span style="font-family: monospace;">InT</span> leads to a near 14% improvement on IMO-Answerbench, beating larger models such as <span style="font-family: monospace;">DeepSeek-R1-0528-Qwen3-8B</span> (18.44%) and <span style="font-family: monospace;">gpt-oss-20b</span> (23.36%) evaluated at a larger budget of 32K.
              </p>
              <table border="1" cellpadding="8" cellspacing="0" style="width: 100%; border-collapse: collapse;">
                <thead>
                    <tr>
                        <th style="text-align: left; border-bottom: 2px solid #333;">Model</th>
                        <th style="text-align: center; border-bottom: 2px solid #333;">IMO-AnswerBench</th>
                        <th style="text-align: center; border-bottom: 2px solid #333;">HMMT 2025 Nov</th>
                        <th style="text-align: center; border-bottom: 2px solid #333;">AMO-Bench pass@8</th>
                        <th style="text-align: center; border-bottom: 2px solid #333;">Apex Shortlist pass@8</th>
                        <th style="text-align: center; border-bottom: 2px solid #333;">D<sub>train</sub></th>
                        <th style="text-align: center; border-bottom: 2px solid #333;">Average</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td style="text-align: left; white-space: nowrap;">Base</td>
                        <td style="text-align: center;">11.68</td>
                        <td style="text-align: center;">41.61</td>
                        <td style="text-align: center;">26.24</td>
                        <td style="text-align: center;">20.79</td>
                        <td style="text-align: center;">5.53</td>
                        <td style="text-align: center;">21.17</td>
                    </tr>
                    <tr>
                        <td style="text-align: left; white-space: nowrap;">+ RL</td>
                        <td style="text-align: center;">23.46</td>
                        <td style="text-align: center;">46.46</td>
                        <td style="text-align: center;">35.21</td>
                        <td style="text-align: center;">22.72</td>
                        <td style="text-align: center;">13.47</td>
                        <td style="text-align: center;">28.26</td>
                    </tr>
                    <tr>
                        <td style="text-align: left; white-space: nowrap;">+ Hint-guided RL</td>
                        <td style="text-align: center;">16.89</td>
                        <td style="text-align: center;">47.27</td>
                        <td style="text-align: center;">33.34</td>
                        <td style="text-align: center;">22.23</td>
                        <td style="text-align: center;">23.06</td>
                        <td style="text-align: center;">28.56</td>
                    </tr>
                    <tr>
                        <td style="text-align: left; white-space: nowrap;">+ SFT on ref. solutions + RL</td>
                        <td style="text-align: center;">11.56</td>
                        <td style="text-align: center;">27.45</td>
                        <td style="text-align: center;">25.19</td>
                        <td style="text-align: center;">20.51</td>
                        <td style="text-align: center;">19.07</td>
                        <td style="text-align: center;">20.76</td>
                    </tr>
                    <tr>
                        <td style="text-align: left; white-space: nowrap;">+ SFT on self-reflections + RL</td>
                        <td style="text-align: center;">15.53</td>
                        <td style="text-align: center;">38.65</td>
                        <td style="text-align: center;"><strong>36.72</strong></td>
                        <td style="text-align: center;">23.93</td>
                        <td style="text-align: center;">23.19</td>
                        <td style="text-align: center;">27.60</td>
                    </tr>
                    <tr style="background-color: #fff3cd; border-top: 2px solid #333; white-space: nowrap;">
                        <td style="text-align: left;"><strong>+ <span style="font-family: monospace;">InT</span> + RL (Ours)</strong></td>
                        <td style="text-align: center;"><strong>25.62</strong></td>
                        <td style="text-align: center;"><strong>49.77</strong></td>
                        <td style="text-align: center;">36.16</td>
                        <td style="text-align: center;"><strong>28.22</strong></td>
                        <td style="text-align: center;"><strong>28.83</strong></td>
                        <td style="text-align: center;"><strong>33.72</strong></td>
                    </tr>
                </tbody>
            </table>
              <!-- <div class="content has-text-justified tw-bg-blue-100 p-3 rounded-lg text-center mb-4" style="margin-top: 10px;">
              <b>Key Findings</b>
              <ul>
                <li>RL with fixed training budget / data mixture hurts in-context exploration</li>
                <li>We propose a coupled curriculum <span style="font-family: monospace;">e3</span>: at each stage, given data mixture <i>D</i>, choose smallest <i>B<sub>tr</sub></i> such that chaining more asymmetries till a budget of 2 ¬∑ <i>B<sub>tr</sub></i> is positively rewarded at RL initialization.</li>
                <li>By fine-tuning Qwen3-1.7B with <span style="font-family: monospace;">e3</span> we outperform &lt; 2B models on AIME‚Äô25, HMMT ‚Äô25.</li>
              </ul>
            </div> -->
            </div>
            <!-- </details> -->
          </div>
        </div>
      </div>
    </section>


            

        
    <!--End BibTex citation -->

    <footer class="footer">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">
              <p>
                This page was built using the
                <a
                  href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                  target="_blank"
                  >Academic Project Page Template</a
                >
                which was adopted from the¬†<a
                  href="https://nerfies.github.io"
                  target="_blank"
                  >Nerfies</a
                >¬†project page.
                <br />
                This website is licensed under a
                <a
                  rel="license"
                  href="http://creativecommons.org/licenses/by-sa/4.0/"
                  target="_blank"
                  >Creative Commons Attribution-ShareAlike 4.0 International
                  License</a
                >.
              </p>
            </div>
          </div>
        </div>
      </div>
    </footer>

    <!-- Statcounter tracking code -->

    <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->
  </body>
</html>
